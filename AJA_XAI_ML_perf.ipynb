{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code shows the implementation and evaluation of a multivariate classifier for hearing loss detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2n0E25gHrB6W",
    "outputId": "b759912f-e88d-4a72-b974-3067b8ff9b50"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,auc,accuracy_score,precision_recall_curve\n",
    "\n",
    "# import dataset and display first rows\n",
    "df = pd.read_csv(\"FILE_PATH\")\n",
    "df.head()\n",
    "# Descriptive statistics for each column\n",
    "features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nOpZJKDwDmNw"
   },
   "outputs": [],
   "source": [
    "# Save features matrix and labels vector\n",
    "X = df.drop(['true_class'], axis = 1).values\n",
    "y = df['true_class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGejO5nfrB6m"
   },
   "outputs": [],
   "source": [
    "# Function that returns the threshold corresponding to the closest point to (1,0) on the ROC curve \n",
    "def find_best_th_roc(ytrain, temp_ytrain_hat):\n",
    "    fpr_train, tpr_train, th_roc_train = roc_curve(ytrain, temp_ytrain_hat)\n",
    "    best_point_roc_x = np.array([0] * fpr_train.shape[0])\n",
    "    best_point_roc_y = np.array([1] * tpr_train.shape[0])\n",
    "    temp_x = (fpr_train - best_point_roc_x)\n",
    "    temp_y = (tpr_train - best_point_roc_y)\n",
    "    temp_sqrt = np.sqrt(np.square(temp_x) + np.square(temp_y))\n",
    "    index_min_temp_sqrt = np.argmin(temp_sqrt)\n",
    "    best_th_roc = th_roc_train[index_min_temp_sqrt]\n",
    "    return best_th_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "B9D2m4wirB69",
    "outputId": "1c366088-f14d-4f26-a18a-388dfa9b6035"
   },
   "outputs": [],
   "source": [
    "n_iterations = 50\n",
    "n_features = 6\n",
    "u = np.zeros(n_features)\n",
    "s = np.zeros(n_features)\n",
    "u_vet = []\n",
    "s_vet = []\n",
    "\n",
    "AUC_tree_vet = []\n",
    "acc_test_tree_vet = []\n",
    "acc_train_tree_vet = []\n",
    "spec_tree_vet=[]\n",
    "sen_tree_vet=[]\n",
    "precision_tree_vet=[]\n",
    "\n",
    "AUC_forest_vet = []\n",
    "acc_test_forest_vet = []\n",
    "acc_train_forest_vet = []\n",
    "spec_forest_vet=[]\n",
    "sen_forest_vet=[]\n",
    "precision_forest_vet=[]\n",
    "\n",
    "# initialize DT and RF with previously tuned hyperparameters \n",
    "tree = DecisionTreeClassifier(criterion = 'gini',max_depth=4,random_state = 9)\n",
    "forest = RandomForestClassifier(n_estimators = 50, criterion = 'gini', max_depth = None, min_samples_split = 2, min_samples_leaf = 1, min_weight_fraction_leaf = 0.0, max_features='auto', max_leaf_nodes = None, min_impurity_decrease = 0.0, bootstrap = True, oob_score = False, n_jobs = None, random_state = None, verbose = 0, warm_start = False, class_weight = None, ccp_alpha = 0.0, max_samples = None)\n",
    "scaler = StandardScaler()\n",
    "for i in range(0,n_iterations): # 50 iterations\n",
    "    # Split the data into training (80%) and test (20%) sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, shuffle = True,  stratify = y) \n",
    "    \n",
    "    '''\n",
    "    #SAVE X train\n",
    "    filename_Xtrain=\"FOREST/X_train/X_train_it\"+str(i)+'.txt'\n",
    "    Xtrain_df=pd.DataFrame(X_train)\n",
    "    Xtrain_df.to_csv(filename_Xtrain,sep=',',header=False,index=False)\n",
    "    \n",
    "    #SAVE X test\n",
    "    filename_Xtest=\"FOREST/X_test/X_test_it\"+str(i)+'.txt'\n",
    "    Xtest_df=pd.DataFrame(X_test)\n",
    "    Xtest_df.to_csv(filename_Xtest,sep=',',header=False,index=False)\n",
    "    \n",
    "    #SAVE y train\n",
    "    filename_ytrain=\"FOREST/y_train/y_train_it\"+str(i)+'.txt'\n",
    "    ytrain_df=pd.DataFrame(y_train)\n",
    "    ytrain_df.to_csv(filename_ytrain,sep=',',header=False,index=False)\n",
    "    \n",
    "    #SAVE y test\n",
    "    filename_ytest=\"FOREST/y_test/y_test_it\"+str(i)+'.txt'\n",
    "    ytest_df=pd.DataFrame(y_test)\n",
    "    ytest_df.to_csv(filename_ytest,sep=',',header=False,index=False)\n",
    "    '''\n",
    "   \n",
    "    # save mean and std to be able to rescale the data outside this notebook\n",
    "    for ind in range (0, n_features):\n",
    "        u[ind] = X_train[:,ind].mean()# u is the mean of the training samples\n",
    "        s[ind] = X_train[:,ind].std()# s is the std of the training samples\n",
    "    u_vet.append(u) \n",
    "    s_vet.append(s)  \n",
    "    u = np.zeros(n_features)\n",
    "    s = np.zeros(n_features)\n",
    "    \n",
    "    # Standard scaler\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    acc_train_best_forest=0\n",
    "    acc_train_best_forest=0\n",
    "    # nested k fold cross-validation\n",
    "    kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 10) \n",
    "\n",
    "    for k, (train, valid) in enumerate (kfold.split(X_train, y_train)):\n",
    "        #DT\n",
    "        tree.fit(X_train[train], y_train[train])  # fit the model on training data\n",
    "        score_tree_kfold_new = tree.score(X_train[valid], y_train[valid])\n",
    "        if score_tree_kfold_new > acc_train_best_tree: # search for the best model \n",
    "            best_tree = tree.fit(X_train[train], y_train[train]) \n",
    "            acc_train_best_tree=score_tree_kfold_new\n",
    "             \n",
    "        #RF\n",
    "        forest.fit(X_train[train], y_train[train])\n",
    "        score_forest_kfold_new = forest.score(X_train[valid], y_train[valid])\n",
    "        if score_forest_kfold_new > acc_train_best_forest:\n",
    "            best_forest = forest.fit(X_train[train], y_train[train])\n",
    "            acc_train_best_forest=score_forest_kfold_new\n",
    "        \n",
    "        \n",
    "    '''Best DT model at iterations i'''\n",
    "    # Save i-th model to a pickle file in the current working directory\n",
    "    pkl_filename_tree = \"tree/MODELS\"/tree_it\"+str(i)+\".pkl\"\n",
    "    with open(pkl_filename_tree, 'wb') as file:\n",
    "        pickle.dump(best_tree, file)  \n",
    "    \n",
    "    # Save DT in dot format for later visualization                          \n",
    "    dotfile = open(\"DT_figures\\DT\"+str(i)+\".dot\", \"w\")\n",
    "    export_graphviz(best_tree, out_file = dotfile, feature_names = ['SRT', 'age','#correct', '%correct','avg_reaction_time','total_test_time'],filled=True)\n",
    "    dotfile.close()\n",
    "    \n",
    "    #evaluate classification performance\n",
    "    acc_train_tree_vet.append(acc_train_best_tree)\n",
    "    \n",
    "    ytest_hat = best_tree.predict_proba(X_test)\n",
    "    y_train_hat = best_tree.predict_proba(X_train)\n",
    "    temp_ytrain_hat = np.copy(y_train_hat[:,1])\n",
    "    best_th_roc = find_best_th_roc(y_train, temp_ytrain_hat)\n",
    "    ytest_hat_l = (ytest_hat[:,1] >= best_th_roc).astype(int)\n",
    "    \n",
    "    #CONFUSION MATRIX on the test set\n",
    "    (tn_tree, fp_tree, fn_tree, tp_tree) = confusion_matrix(y_test, ytest_hat_l).ravel()  \n",
    "    accuracy_test = (tn_tree + tp_tree) / (tn_tree + tp_tree + fn_tree + fp_tree)\n",
    "    acc_test_tree_vet.append(accuracy_test)    \n",
    "    # Compute recall (sensitivity) = TP/(TP+FN) \n",
    "    sen_tree_vet.append(tp_tree / (tp_tree + fn_tree))    \n",
    "    # Compute true negative rate (specificity) = TN /(TN+FP)\n",
    "    spec_tree_vet.append(tn_tree / (tn_tree + fp_tree))    \n",
    "    #Compute precision (positive predicted value) = TP/(TP+FP)\n",
    "    precision_tree_vet.append(tp_tree  / (tp_tree  + fp_tree )    \n",
    "    #Compute AUC\n",
    "    fpr, tpr, th_roc = roc_curve(y_test, ytest_hat[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    AUC_tree_vet.append(roc_auc)\n",
    "    \n",
    "                              \n",
    "    '''Best RF model at iterations i'''\n",
    "    # Save i-th model to a pickle file in the current working directory\n",
    "    pkl_filename_Forest = \"FOREST/MODELS\"/Forest_it\"+str(i)+\".pkl\"\n",
    "    with open(pkl_filename_Forest, 'wb') as file:\n",
    "        pickle.dump(best_forest, file)   \n",
    "        \n",
    "    #evaluate classification performance\n",
    "    acc_train_forest_vet.append(acc_train_best_forest)\n",
    "    \n",
    "    ytest_hat = best_forest.predict_proba(X_test)\n",
    "    y_train_hat = best_forest.predict_proba(X_train)\n",
    "    temp_ytrain_hat = np.copy(y_train_hat[:,1])\n",
    "    best_th_roc = find_best_th_roc(y_train, temp_ytrain_hat)\n",
    "    ytest_hat_l = (ytest_hat[:,1] >= best_th_roc).astype(int)\n",
    "    \n",
    "    #CONFUSION MATRIX on the test set\n",
    "    (tn_forest, fp_forest, fn_forest, tp_forest) = confusion_matrix(y_test, ytest_hat_l).ravel()  \n",
    "    accuracy_test = (tn_forest + tp_forest) / (tn_forest + tp_forest + fn_forest + fp_forest)\n",
    "    acc_test_forest_vet.append(accuracy_test)    \n",
    "    # Compute recall (sensitivity) = TP/(TP+FN) \n",
    "    sen_forest_vet.append(tp_forest / (tp_forest + fn_forest))    \n",
    "    # Compute true negative rate (specificity) = TN /(TN+FP)\n",
    "    spec_forest_vet.append(tn_forest / (tn_forest + fp_forest))    \n",
    "    #Compute precision (positive predicted value) = TP/(TP+FP)\n",
    "    precision_forest_vet.append(tp_forest  / (tp_forest  + fp_forest )    \n",
    "    #Compute AUC\n",
    "    fpr, tpr, th_roc = roc_curve(y_test, ytest_hat[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    AUC_forest_vet.append(roc_auc)\n",
    "    \n",
    "#save features mean and std (for each trainining set) for inverse normalization\n",
    "df_mean = pd.DataFrame(u_vet,columns=['SRT_mean','Age_mean','correct_mean','percentage_mean','Avg_reaction_time_mean','Total_test_time_mean'])\n",
    "df_std= pd.DataFrame(s_vet,columns=['SRT_std','Age_std','correct_std','percentage_std','Avg_reaction_time_std','Total_test_time_std'])\n",
    "df_mean.to_csv(\"FOREST/mean_normalization.txt\",sep=',',header=True,index=False)\n",
    "df_std.to_csv(\"FOREST/std_normalization.txt\",sep=',',header=True,index=False)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "posgN5JOrB7F",
    "outputId": "30af6039-85ae-4257-a288-579aa2314a87"
   },
   "outputs": [],
   "source": [
    "'''Average DT classification performance over 50 iterations'''\n",
    "print ('DT classification performance:')\n",
    "print('Train accuracy: '+str(round(np.array(acc_train_tree_vet).mean(),3))+' ±  '+str(round(np.array(acc_train_tree_vet).std(),2)))\n",
    "print('Test accuracy: '+str(round(np.array(acc_test_tree_vet).mean(),3))+' ±  '+str(round( np.array(acc_test_tree_vet).std(),2)))\n",
    "print('AUC: '+str(round(np.array(AUC_tree_vet).mean(),3))+' ±  '+str(round(np.array(AUC_tree_vet).std(),2)))\n",
    "print('Specificity: '+str(round(np.array(spec_tree_vet).mean(),3))+' ±  '+str(round(np.array(spec_tree_vet).std(),2)))\n",
    "print('Sensitivity: '+str(round(np.array(sen_tree_vet).mean(),3))+' ±  '+str(round(np.array(sen_tree_vet).std(),2)))\n",
    "print('Precision: '+str(round(np.array(precision_tree_vet).mean(),3))+' ±  '+str(round(np.array(precision_tree_vet).std(),2)))\n",
    "\n",
    "'''Average RF classification performance over 50 iterations'''\n",
    "print ('RF classification performance:')\n",
    "print('Train accuracy: '+str(round(np.array(acc_train_forest_vet).mean(),3))+' ±  '+str(round(np.array(acc_train_forest_vet).std(),2)))\n",
    "print('Test accuracy: '+str(round(np.array(acc_test_forest_vet).mean(),3))+' ±  '+str(round( np.array(acc_test_forest_vet).std(),2)))\n",
    "print('AUC: '+str(round(np.array(AUC_forest_vet).mean(),3))+' ±  '+str(round(np.array(AUC_forest_vet).std(),2)))\n",
    "print('Specificity: '+str(round(np.array(spec_forest_vet).mean(),3))+' ±  '+str(round(np.array(spec_forest_vet).std(),2)))\n",
    "print('Sensitivity: '+str(round(np.array(sen_forest_vet).mean(),3))+' ±  '+str(round(np.array(sen_forest_vet).std(),2)))\n",
    "print('Precision: '+str(round(np.array(precision_forest_vet).mean(),3))+' ±  '+str(round(np.array(precision_forest_vet).std(),2)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copia di Random_Forest.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
